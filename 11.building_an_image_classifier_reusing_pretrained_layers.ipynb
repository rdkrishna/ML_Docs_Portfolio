{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "* Training neural network model_A on data related to 6 classes, \n",
    "* Then train another neural network model_B on remaining 2 classes.\n",
    "* Pre-trained weights are used to tune last layer so as to classify these 2 classes (Transfer learning), \n",
    "* And compare results of 2 models - model_B (normal training) and model_B_on_A (transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = X_train_full[:30000]\n",
    "y_train_full = y_train_full[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[:5000]\n",
    "y_test = y_test[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalising\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Splitting train_full into valid (first 5000) and train (remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_A: all images of all items except for sandals and shirts (classes 5 and 6). \n",
    "\n",
    "X_train_B: a much smaller training set of just the first 200 images of sandals or shirts. The validation set and the test set are also split this way, but without restricting the number of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why are we doing this?**\n",
    "\n",
    "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using Dense layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A), (X[y_5_or_6], y_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Creating Keras neural Network\n",
    "## Then Flattening input image to model\n",
    "## Add 5 dense layers with n_hidden number of neurons and selu activation\n",
    "## Add Final dense layer with 8 neuron and softmax activation (for classifying 8 classes of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss= \"sparse_categorical_crossentropy\",\n",
    "    optimizer= keras.optimizers.SGD(learning_rate=1e-3),\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "622/622 [==============================] - 2s 3ms/step - loss: 0.3108 - accuracy: 0.8909 - val_loss: 0.3083 - val_accuracy: 0.8944\n",
      "Epoch 2/5\n",
      "622/622 [==============================] - 2s 3ms/step - loss: 0.2999 - accuracy: 0.8961 - val_loss: 0.3081 - val_accuracy: 0.8949\n",
      "Epoch 3/5\n",
      "622/622 [==============================] - 2s 3ms/step - loss: 0.2917 - accuracy: 0.8983 - val_loss: 0.3208 - val_accuracy: 0.8891\n",
      "Epoch 4/5\n",
      "622/622 [==============================] - 2s 3ms/step - loss: 0.2841 - accuracy: 0.9024 - val_loss: 0.2867 - val_accuracy: 0.9056\n",
      "Epoch 5/5\n",
      "622/622 [==============================] - 2s 3ms/step - loss: 0.2776 - accuracy: 0.9038 - val_loss: 0.2882 - val_accuracy: 0.8996\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=5,\n",
    "            validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and Fit the Model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/envs/tensorflow2/lib/python3.6/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "model_B.compile(loss= \"binary_crossentropy\",\n",
    "    optimizer= keras.optimizers.SGD(lr=1e-3),\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.2678 - accuracy: 0.5050 - val_loss: 0.1301 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0910 - accuracy: 0.5050 - val_loss: 0.0765 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.5050 - val_loss: 0.0565 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.5050 - val_loss: 0.0456 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.5050 - val_loss: 0.0389 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=5,\n",
    "            validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new model based on existing model A\n",
    "check number of trainable parameters for previously trained model_B.\n",
    "\n",
    "Create a new model model_B_on_A which has the pre-trained parameters of model_A but customized final dense layer with only 1 neuron.\n",
    "\n",
    "Finally, Compare the performance of both the models - model_B and model_B_on_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trainable params = 275,801"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Creating model_A_clone, so when its weights are changed, it doesn't affect model_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.02448623, -0.00877784, -0.0218912 , ..., -0.02766109,\n",
       "          0.03859095, -0.06889368],\n",
       "        [ 0.0047635 , -0.03105379, -0.05866694, ...,  0.00603038,\n",
       "         -0.02763411, -0.04165162],\n",
       "        [-0.06191033, -0.0690196 ,  0.07101057, ..., -0.04237805,\n",
       "          0.07121388, -0.07332943],\n",
       "        ...,\n",
       "        [-0.03043905,  0.02141099, -0.05357783, ..., -0.0005746 ,\n",
       "          0.00270009,  0.05603222],\n",
       "        [ 0.07061882, -0.06976722,  0.07059094, ..., -0.00371876,\n",
       "          0.00033509,  0.02873355],\n",
       "        [-0.06023801,  0.01576762, -0.02584785, ..., -0.00528044,\n",
       "          0.00270329, -0.067969  ]], dtype=float32),\n",
       " array([-4.23583295e-03,  4.98862588e-04, -5.68915624e-03, -1.54783111e-03,\n",
       "        -1.88093865e-03, -6.74478943e-03,  4.95258765e-03, -4.44602128e-03,\n",
       "        -1.30842754e-03,  3.82664357e-03, -3.83113627e-03, -4.57089022e-03,\n",
       "         1.22007693e-03,  1.67986451e-04, -4.97296173e-03, -1.06554257e-03,\n",
       "        -4.71460586e-03, -3.02621326e-03, -7.97565561e-03, -3.63979116e-03,\n",
       "         3.63103136e-05,  3.79074598e-03,  3.62338615e-03,  1.24127476e-03,\n",
       "         3.27674294e-04, -5.73116029e-03, -2.65241670e-03, -1.56434102e-03,\n",
       "         3.44861619e-05,  1.65464322e-03, -2.46176659e-03, -2.49864487e-03,\n",
       "         7.12137995e-03,  4.79220971e-03, -5.88329136e-03,  1.08472705e-02,\n",
       "         3.93463625e-03, -3.33114457e-03, -6.23310276e-04, -6.97948737e-03,\n",
       "        -1.17372805e-02, -3.38212377e-03, -2.23412202e-03,  3.97977140e-03,\n",
       "        -4.76028770e-03,  3.81875457e-03, -4.00760537e-03, -3.16297216e-03,\n",
       "         1.75031993e-04,  4.56877425e-03,  3.80648905e-03, -4.69010742e-03,\n",
       "         1.32571161e-03, -1.19081768e-03, -2.40963325e-03, -9.39554255e-03,\n",
       "        -1.08111557e-02,  3.29689193e-03,  3.73698841e-03,  2.26502353e-03,\n",
       "         9.54298768e-04, -3.37005360e-03,  1.70520460e-03, -3.05954949e-03,\n",
       "         1.20821416e-04, -1.23018574e-03,  1.18696971e-05, -2.52939668e-03,\n",
       "         5.86766144e-03,  3.52690555e-03,  4.18999791e-03,  6.71168603e-03,\n",
       "        -8.82540597e-04,  4.53961547e-03,  9.64509149e-04, -2.89606210e-03,\n",
       "         2.80657667e-03,  2.26312201e-03, -6.26080902e-03, -5.61080175e-04,\n",
       "         2.13567074e-03,  7.82355294e-03, -1.23924774e-03, -1.34902261e-03,\n",
       "        -6.98890490e-03,  7.30140251e-04,  2.43118778e-03,  9.10215720e-04,\n",
       "        -1.89170497e-03,  4.87856008e-03, -2.16189935e-03, -9.28764511e-03,\n",
       "        -2.61337776e-03, -8.24393705e-04, -7.16558378e-03, -5.76220406e-03,\n",
       "        -1.78738288e-03,  1.24077266e-03, -2.11899751e-04,  4.27454012e-03,\n",
       "         2.38746777e-03, -2.13220206e-04, -3.91214620e-03, -6.19932730e-03,\n",
       "        -6.13042386e-03, -6.84943469e-03,  2.44431547e-03, -1.62650319e-03,\n",
       "         7.95281143e-04,  3.67357139e-03,  2.77479342e-03,  2.67412513e-03,\n",
       "         1.47627229e-02, -3.23348702e-03, -1.08275784e-03,  2.06268323e-03,\n",
       "         5.54011762e-03,  1.60553853e-03, -8.05129122e-04,  1.04475757e-02,\n",
       "        -2.80528562e-03,  6.14583958e-04, -1.13655033e-03,  8.53936467e-03,\n",
       "         1.02001643e-02, -3.15498072e-03, -4.11422399e-04,  3.51797114e-03,\n",
       "         1.31379114e-03, -1.01248396e-03, -5.36632200e-04,  1.08749804e-03,\n",
       "        -3.11509444e-04, -3.24571133e-03,  2.43216782e-04,  6.05571689e-03,\n",
       "        -4.04078932e-03,  5.35455393e-03, -1.25461752e-02, -4.40911157e-03,\n",
       "         6.32765470e-03, -5.63715771e-03, -6.64989417e-03,  4.92623216e-03,\n",
       "        -1.38953875e-03, -3.64618842e-04,  5.48478356e-03,  3.12677911e-03,\n",
       "        -1.91713497e-03,  6.42678700e-03,  4.61984333e-03,  4.94430889e-04,\n",
       "        -2.93075945e-03,  2.43690726e-03,  1.97218033e-03, -5.76837780e-03,\n",
       "         8.01838189e-03,  1.96231855e-03,  4.26282082e-03, -2.28341133e-03,\n",
       "         7.50090787e-03,  2.44858977e-03, -4.64289356e-03, -1.01479469e-02,\n",
       "        -5.10759128e-04,  3.49096279e-03, -2.04922887e-03, -6.25563506e-03,\n",
       "        -3.90567759e-04, -3.69405490e-03, -3.86616401e-03, -4.85246535e-03,\n",
       "         3.69910710e-03, -3.52060329e-03, -6.44262135e-03, -1.50554429e-03,\n",
       "        -2.60162749e-03, -5.32759028e-03,  4.66950797e-03,  3.92834377e-03,\n",
       "        -1.67559471e-03, -8.11441615e-03,  2.82778265e-03,  5.30192629e-03,\n",
       "         2.34809448e-03, -2.70913891e-03, -4.74038487e-03,  1.84674631e-03,\n",
       "         9.36276745e-04, -7.12411432e-03,  1.17113255e-03, -7.69793463e-04,\n",
       "        -2.46516732e-03, -5.72073087e-03, -4.59574454e-04, -9.50241112e-04,\n",
       "         5.63459587e-04,  8.05492164e-04, -1.79611950e-03, -6.01014774e-03,\n",
       "        -7.90215470e-03,  1.18548970e-03, -1.35683047e-03, -1.93948770e-04,\n",
       "        -3.61524476e-03,  1.30828097e-03,  8.55083112e-03, -2.33714911e-03,\n",
       "        -1.41922594e-03,  3.70178663e-04,  3.04470654e-03, -3.35846399e-03,\n",
       "        -1.61949673e-03, -9.26983717e-04, -1.78270857e-03, -3.83661856e-04,\n",
       "        -4.82556783e-03,  1.26080075e-03, -6.69644633e-03,  6.85890112e-03,\n",
       "        -5.87851834e-03,  7.51693035e-03, -2.70939339e-03, -5.64145064e-03,\n",
       "        -3.74094187e-03, -3.38687585e-03, -5.42153744e-03,  1.06231077e-03,\n",
       "        -3.65908002e-03, -1.10385159e-03, -5.37249551e-04, -2.35380861e-03,\n",
       "        -1.12220235e-02,  7.83451367e-04, -1.20786298e-03,  1.45464565e-03,\n",
       "        -3.40477959e-03, -6.56625442e-03,  4.78951115e-04, -2.11095274e-03,\n",
       "        -1.47311820e-03,  2.80082808e-03,  2.40458734e-03,  1.77779328e-03,\n",
       "         6.06154650e-03,  9.79682081e-04,  5.91383129e-03, -4.29141382e-03,\n",
       "         6.68140175e-03, -1.36497070e-03, -5.68898953e-03,  1.99144054e-03,\n",
       "        -2.01779930e-03, -6.19140547e-03,  2.19166838e-03, -5.07074874e-04,\n",
       "        -2.47804890e-03, -1.15839094e-02,  3.75509053e-03,  9.05326195e-03,\n",
       "        -7.59537390e-04,  4.16710973e-03, -4.69257729e-03,  2.66944931e-04,\n",
       "        -5.51142497e-03,  5.06851682e-03, -5.95934782e-03,  3.67168407e-03,\n",
       "         1.43816252e-03,  3.46487807e-03, -3.38405301e-03,  8.41582194e-03,\n",
       "         5.34290308e-03,  1.68849435e-03, -1.21177429e-04,  1.02822296e-03,\n",
       "         5.15152328e-03, -8.42800000e-05,  4.78967978e-03, -1.41376513e-03,\n",
       "         4.62351320e-03, -1.61817356e-03,  2.04216945e-03,  2.11795862e-03,\n",
       "        -7.31437188e-03, -7.92910997e-03,  2.71414960e-04,  2.38219416e-03,\n",
       "        -4.02513426e-03,  5.14266361e-03, -3.68284690e-03, -4.68221446e-03,\n",
       "        -3.43598682e-03,  3.48365190e-03, -5.30787092e-03, -1.37147889e-03,\n",
       "        -1.08546214e-04,  4.34588641e-03,  5.18908165e-03,  4.14156681e-03],\n",
       "       dtype=float32),\n",
       " array([[ 0.04550762, -0.00542928,  0.1084742 , ...,  0.05424558,\n",
       "         -0.09825415,  0.10837187],\n",
       "        [-0.01037718, -0.04049618, -0.01178451, ..., -0.06828707,\n",
       "         -0.05228093, -0.10634247],\n",
       "        [ 0.07303185,  0.11359467,  0.06448147, ...,  0.04448149,\n",
       "         -0.04164799,  0.10819828],\n",
       "        ...,\n",
       "        [-0.08370833,  0.1235486 , -0.11266434, ...,  0.11065789,\n",
       "         -0.10574296,  0.05034587],\n",
       "        [-0.1164589 , -0.07013571,  0.00561021, ..., -0.00228991,\n",
       "          0.01616161,  0.02371239],\n",
       "        [-0.11716298,  0.04642912,  0.11834513, ..., -0.07593591,\n",
       "          0.12670028, -0.10465012]], dtype=float32),\n",
       " array([-3.04642785e-03,  6.64283428e-03,  1.71894371e-03, -4.10107756e-03,\n",
       "         7.61418778e-04,  1.95520860e-03, -5.72755001e-03, -6.31620362e-03,\n",
       "         6.10843161e-03,  8.07873067e-03, -9.71061701e-04,  4.97011747e-03,\n",
       "         1.48295355e-03, -8.33486629e-05,  8.98888102e-05,  2.21837964e-03,\n",
       "        -1.36911741e-03, -1.71776803e-03, -7.99383502e-03,  9.72084701e-03,\n",
       "         4.66723647e-03, -4.90021077e-04,  9.14447848e-03,  1.67691952e-03,\n",
       "        -7.67484773e-03,  1.39967108e-03,  3.80662153e-03, -1.55082555e-03,\n",
       "        -1.85660145e-03, -1.36712880e-03,  8.65012815e-04, -5.66916587e-03,\n",
       "         2.27758370e-04, -2.49458617e-03, -1.90559425e-03, -6.53625652e-03,\n",
       "         4.47652303e-03, -1.49233860e-03, -3.37345828e-03, -2.22342950e-03,\n",
       "         2.46935384e-03, -6.05930714e-03, -4.96906182e-03,  7.97477784e-04,\n",
       "         5.08373650e-03, -4.78778500e-03,  1.76438119e-03, -3.31241265e-03,\n",
       "         1.18373544e-03, -3.29964771e-03, -2.51144357e-03, -1.37602398e-03,\n",
       "        -6.39035692e-03, -1.51355751e-03, -2.69210874e-03,  1.12113438e-03,\n",
       "         7.52336858e-03,  5.63781057e-03,  4.04015649e-03, -3.05678602e-03,\n",
       "         4.52514691e-03,  5.99113666e-03,  2.59688217e-03,  1.83213700e-03,\n",
       "         1.23474449e-02, -9.59867984e-03, -1.42535707e-03,  2.10485980e-03,\n",
       "        -2.22524439e-04,  1.31039955e-02,  1.16713427e-03,  1.26011204e-03,\n",
       "        -6.74436195e-03, -4.66685183e-03, -1.03757693e-03, -3.56148183e-03,\n",
       "        -6.33543776e-03,  2.77557038e-03,  1.10564148e-03, -3.61254718e-03,\n",
       "         2.00699735e-03, -5.13998559e-04,  2.77514360e-03, -3.74401367e-04,\n",
       "         1.83719757e-03, -9.91424918e-03, -2.82948633e-04,  4.23811655e-03,\n",
       "        -4.15674783e-03, -1.23937076e-04, -1.09209352e-04, -2.65496015e-03,\n",
       "        -3.45004071e-03, -3.42263142e-03,  4.01791232e-03,  4.62295534e-03,\n",
       "        -3.60336178e-03, -2.26697279e-03, -1.19416683e-03, -6.96729030e-03],\n",
       "       dtype=float32),\n",
       " array([[ 0.10278875,  0.05205544, -0.18810798, ..., -0.08452796,\n",
       "         -0.00696503, -0.09798504],\n",
       "        [ 0.09087802,  0.08776662, -0.13188086, ..., -0.12433888,\n",
       "          0.05638721,  0.12661047],\n",
       "        [-0.18371977,  0.03124744, -0.08721845, ..., -0.20325376,\n",
       "         -0.06299735, -0.02582738],\n",
       "        ...,\n",
       "        [ 0.07393161,  0.13131166, -0.06965756, ..., -0.065667  ,\n",
       "         -0.15537679,  0.10245793],\n",
       "        [-0.1043403 , -0.07783148,  0.01761626, ..., -0.1012469 ,\n",
       "          0.10138014, -0.14436577],\n",
       "        [-0.0616914 , -0.19805695, -0.17854784, ..., -0.11371392,\n",
       "         -0.02703487, -0.07297056]], dtype=float32),\n",
       " array([ 0.0050357 ,  0.00092055, -0.00101251,  0.00302414,  0.00735867,\n",
       "        -0.00066873,  0.00043163, -0.00406878,  0.00034604, -0.00540238,\n",
       "         0.00217789,  0.00368436, -0.00091403,  0.00350332, -0.00996179,\n",
       "         0.00616449, -0.00209825,  0.00221954, -0.00086377, -0.00081853,\n",
       "         0.01105576,  0.00415442, -0.00193412,  0.00759269, -0.00325836,\n",
       "        -0.00066612, -0.00171974, -0.00021438,  0.00028161, -0.00014645,\n",
       "         0.00061837,  0.00272111,  0.00407609,  0.00225996,  0.0010358 ,\n",
       "        -0.00446491, -0.00454646,  0.00211047, -0.00462587, -0.00395013,\n",
       "        -0.00597212, -0.00466538,  0.00288235,  0.00148098, -0.01230281,\n",
       "         0.00391241,  0.00470077,  0.00147392, -0.00399222, -0.00169438],\n",
       "       dtype=float32),\n",
       " array([[ 0.11531921, -0.07994609,  0.0308376 , ...,  0.01811401,\n",
       "         -0.22442603, -0.22758384],\n",
       "        [ 0.15606147,  0.134466  ,  0.15433669, ...,  0.0362059 ,\n",
       "         -0.22268267,  0.01250467],\n",
       "        [-0.1735511 ,  0.06055553, -0.17039283, ...,  0.19362012,\n",
       "          0.14080316,  0.03081766],\n",
       "        ...,\n",
       "        [ 0.0708064 , -0.17801395,  0.12802139, ..., -0.02604364,\n",
       "          0.12317252, -0.19413473],\n",
       "        [ 0.10000228, -0.00890962,  0.14841838, ..., -0.10502398,\n",
       "         -0.04185364,  0.1503758 ],\n",
       "        [ 0.07103296,  0.10034748,  0.20264632, ..., -0.15938145,\n",
       "         -0.01697059,  0.17337069]], dtype=float32),\n",
       " array([ 2.7002948e-03,  1.5426476e-03,  1.9471358e-03, -6.6290363e-03,\n",
       "        -3.1151043e-03,  7.8154728e-03,  9.4906165e-04, -4.1852337e-03,\n",
       "         4.6069636e-03,  2.5179135e-04, -2.7351759e-03,  7.9060055e-04,\n",
       "         5.3553823e-03,  4.5463410e-03, -4.5352704e-03,  2.0059205e-03,\n",
       "        -5.4485048e-03, -1.0016142e-02,  7.1603945e-03,  1.1288504e-03,\n",
       "         1.2691284e-03,  6.7016744e-04, -8.4985903e-04,  1.4873642e-03,\n",
       "        -2.5101891e-03, -1.3022146e-03,  1.1040969e-02,  4.0086838e-03,\n",
       "        -1.8688554e-03, -3.2019720e-03,  7.7173756e-03,  1.4234190e-03,\n",
       "         7.0048585e-03,  7.1538103e-05, -5.4890697e-04,  5.6762705e-03,\n",
       "        -1.2157332e-03, -1.2012960e-03, -1.9385130e-04,  4.0682945e-03,\n",
       "         2.8900169e-03,  2.4646644e-03, -3.7397296e-04, -1.2647612e-04,\n",
       "         5.4763043e-03,  2.4591957e-03,  1.1922660e-02,  2.4393152e-03,\n",
       "         3.5041815e-03,  2.9668596e-04], dtype=float32),\n",
       " array([[ 0.15127641,  0.00098859, -0.06048671, ...,  0.23805425,\n",
       "          0.14461896, -0.1779805 ],\n",
       "        [-0.0387067 , -0.22075698,  0.16181602, ...,  0.1183152 ,\n",
       "         -0.0216569 ,  0.13768256],\n",
       "        [ 0.08837753,  0.01341923,  0.1998977 , ...,  0.22330089,\n",
       "         -0.14249365, -0.20137176],\n",
       "        ...,\n",
       "        [-0.18106976, -0.0557643 , -0.16946205, ..., -0.09419037,\n",
       "          0.24025083, -0.06543426],\n",
       "        [ 0.08269478, -0.0040348 ,  0.05223275, ..., -0.16855854,\n",
       "         -0.12849943,  0.01341386],\n",
       "        [-0.22277048, -0.12441894, -0.03695507, ..., -0.17615013,\n",
       "          0.1867582 , -0.1716711 ]], dtype=float32),\n",
       " array([-2.1046316e-03,  1.8046637e-03,  6.8363798e-04, -1.9324424e-03,\n",
       "         1.3923162e-03,  1.3212666e-03,  6.6130119e-04,  4.6096105e-04,\n",
       "        -7.7338860e-04, -2.7364206e-03,  5.8404487e-03, -1.4845011e-03,\n",
       "         7.2419958e-04, -4.2537479e-03, -5.2816714e-03,  1.5725747e-03,\n",
       "         5.5474783e-03,  9.7970606e-04, -2.6396536e-03,  7.9844519e-03,\n",
       "         5.0374446e-03,  8.1021956e-04, -2.3635164e-04, -4.2430880e-03,\n",
       "        -1.1888315e-03, -8.8326260e-04, -3.6814646e-03, -3.7987803e-03,\n",
       "         2.6353269e-03, -9.3907421e-04, -3.6277461e-03,  3.3216942e-03,\n",
       "         4.4121961e-03, -1.1098233e-05, -2.0372409e-03, -2.1640534e-04,\n",
       "         1.4702682e-03,  6.9478126e-03,  2.0408775e-03,  1.0888991e-03,\n",
       "         7.6837791e-03,  4.3284455e-03, -2.2501573e-03, -8.8307279e-04,\n",
       "         2.5498844e-03,  1.1411827e-02,  9.5268719e-05, -1.3030936e-04,\n",
       "        -5.9042391e-03, -7.0850509e-03], dtype=float32),\n",
       " array([[ 3.40949655e-01, -3.24117869e-01, -1.17517427e-01,\n",
       "         -2.09953815e-01,  1.27920747e-01,  1.61320746e-01,\n",
       "         -2.62004077e-01, -1.00648701e-01],\n",
       "        [-2.22930774e-01,  8.32779557e-02,  3.31131548e-01,\n",
       "         -2.87519723e-01, -1.91105142e-01,  2.72000790e-01,\n",
       "         -2.92199016e-01, -1.68901309e-01],\n",
       "        [ 1.17513172e-01,  1.76459640e-01,  2.25145087e-01,\n",
       "          5.91132930e-03,  1.63759291e-01,  1.04260311e-01,\n",
       "          3.60784702e-06, -1.83442697e-01],\n",
       "        [ 2.82256186e-01, -5.70550673e-02,  1.97271630e-01,\n",
       "          1.43725350e-01,  1.09928213e-01, -1.61221951e-01,\n",
       "          1.64976031e-01, -1.68588966e-01],\n",
       "        [ 2.74929166e-01,  1.28537416e-01,  1.27573431e-01,\n",
       "          1.22266650e-01,  2.89007545e-01, -1.50218442e-01,\n",
       "         -1.03962094e-01,  2.55965203e-01],\n",
       "        [-2.85404269e-03,  1.59551010e-01, -1.39041290e-01,\n",
       "         -8.76781791e-02,  4.39877287e-02,  1.67943284e-01,\n",
       "         -2.93729622e-02,  3.72248292e-02],\n",
       "        [ 6.95782080e-02, -1.97372586e-01,  8.93854201e-02,\n",
       "         -1.72643751e-01, -2.75512654e-02,  1.14266329e-01,\n",
       "          4.37110253e-02,  6.93235695e-02],\n",
       "        [ 2.86393642e-01, -2.80173980e-02, -2.15599179e-01,\n",
       "         -1.61461346e-02,  2.98898250e-01,  2.44128674e-01,\n",
       "          1.85469925e-01, -7.27410167e-02],\n",
       "        [-3.18555087e-02,  1.33537754e-01,  4.01364751e-02,\n",
       "         -5.30078709e-02, -2.88678527e-01, -1.88936844e-01,\n",
       "         -3.30672801e-01, -1.03167988e-01],\n",
       "        [ 2.84847379e-01, -2.64730155e-01,  2.71863341e-01,\n",
       "         -2.60477662e-01, -1.63656309e-01,  1.88004717e-01,\n",
       "          1.82029277e-01,  8.60267654e-02],\n",
       "        [ 3.26866001e-01, -3.06445777e-01, -3.44434172e-01,\n",
       "         -2.14106992e-01, -1.50952965e-01,  1.46286756e-01,\n",
       "          1.54926896e-01, -8.10083002e-02],\n",
       "        [-4.12674882e-02,  2.25420490e-01,  1.61354363e-01,\n",
       "         -3.34204704e-01,  1.45657793e-01, -1.42696112e-01,\n",
       "         -1.74638137e-01,  3.31080079e-01],\n",
       "        [-1.03716314e-01, -1.94194779e-01, -2.45169535e-01,\n",
       "         -1.86528563e-01,  4.16107140e-02,  4.91442867e-02,\n",
       "         -2.55798787e-01,  1.95295047e-02],\n",
       "        [-2.22988978e-01, -4.94442228e-03,  3.11008338e-02,\n",
       "         -2.86869779e-02,  2.83719420e-01, -2.92215616e-01,\n",
       "          2.66417325e-01, -8.96757171e-02],\n",
       "        [-1.39717713e-01,  2.38284931e-01, -2.13018823e-02,\n",
       "         -3.06981087e-01,  2.49405473e-01, -1.75811797e-01,\n",
       "          8.40849429e-02, -1.55570969e-01],\n",
       "        [ 1.12463407e-01, -2.79600590e-01,  1.29048586e-01,\n",
       "          3.05156589e-01, -2.02576190e-01, -3.17771643e-01,\n",
       "         -1.21459238e-01, -1.85967863e-01],\n",
       "        [ 4.82185371e-02, -2.24160597e-01,  5.19655906e-02,\n",
       "          1.32802144e-01, -2.64061064e-01, -2.18748033e-01,\n",
       "          7.26916716e-02,  2.55474776e-01],\n",
       "        [ 8.20509717e-03, -1.77067205e-01, -3.91088501e-02,\n",
       "         -8.72106701e-02,  8.02379102e-03, -3.13887626e-01,\n",
       "         -2.74013221e-01,  3.37922782e-01],\n",
       "        [-1.01952806e-01,  9.04932171e-02,  3.26676100e-01,\n",
       "         -3.08121536e-02,  1.85885400e-01,  1.03413522e-01,\n",
       "         -2.48973072e-01,  2.27299199e-01],\n",
       "        [ 2.15280682e-01,  6.48904475e-04,  2.41937801e-01,\n",
       "          1.91942722e-01, -1.64270341e-01,  1.20024741e-01,\n",
       "          2.43476287e-01, -3.16601783e-01],\n",
       "        [ 1.00248702e-01,  2.08616313e-02,  5.60577363e-02,\n",
       "         -2.77244776e-01, -2.14903146e-01,  7.51880333e-02,\n",
       "         -3.97263914e-02, -4.75974828e-02],\n",
       "        [-2.17225030e-01, -3.76306891e-01,  1.73797444e-01,\n",
       "          9.79104042e-02, -1.84672892e-01,  2.72479770e-03,\n",
       "          2.01831773e-01,  5.92650063e-02],\n",
       "        [ 2.50220180e-01, -1.89219505e-01, -1.12124800e-03,\n",
       "         -2.89477259e-01,  2.11614832e-01, -1.36671746e-02,\n",
       "         -1.04395729e-02, -2.73475260e-01],\n",
       "        [ 2.75968224e-01, -1.54466122e-01, -2.57427633e-01,\n",
       "         -2.42131978e-01,  2.86510527e-01, -3.05960953e-01,\n",
       "         -1.88529119e-01, -1.64939687e-01],\n",
       "        [-2.95670569e-01,  3.70267689e-01, -2.49956742e-01,\n",
       "          3.63457166e-02, -1.15535662e-01, -2.58081090e-02,\n",
       "         -1.26640815e-02, -2.97403038e-01],\n",
       "        [-5.73870577e-02, -7.79872835e-02,  5.83779104e-02,\n",
       "         -2.43144542e-01,  2.34644085e-01,  6.55068830e-02,\n",
       "         -3.47081453e-01, -1.20023899e-01],\n",
       "        [-1.98026150e-01, -2.51358300e-01,  3.37991826e-02,\n",
       "         -1.05649814e-01,  1.27031401e-01, -1.64971396e-01,\n",
       "          3.67388010e-01, -3.09578657e-01],\n",
       "        [ 2.13724732e-01,  2.31159911e-01, -1.31989047e-01,\n",
       "         -2.51969665e-01,  3.06248218e-01, -2.81931460e-01,\n",
       "          3.42255682e-02, -2.37829760e-01],\n",
       "        [ 1.53448328e-01,  8.01877026e-03,  3.12468886e-01,\n",
       "          2.09226981e-01,  1.37183413e-01, -5.42134456e-02,\n",
       "         -2.45114103e-01,  1.42201167e-02],\n",
       "        [ 1.13560557e-01, -2.24202678e-01,  3.13548267e-01,\n",
       "          2.53549397e-01,  9.71507952e-02, -6.36664405e-02,\n",
       "          7.02707749e-03,  2.65350495e-03],\n",
       "        [-3.24242115e-02,  1.20558880e-01, -2.39979655e-01,\n",
       "          9.05556325e-03, -6.35238439e-02, -3.07640940e-01,\n",
       "          1.80261314e-01,  2.18231753e-01],\n",
       "        [-1.86451301e-01,  1.49730295e-01,  1.98113322e-01,\n",
       "          3.07947099e-01, -2.47187868e-01, -2.18766138e-01,\n",
       "         -3.15883011e-01,  2.00168401e-01],\n",
       "        [ 1.70517966e-01,  3.09856031e-02, -9.80104133e-02,\n",
       "         -4.52578217e-02, -1.13627151e-01, -1.33107454e-01,\n",
       "          1.81943014e-01,  7.51872733e-02],\n",
       "        [ 9.86128747e-02,  2.91834384e-01, -2.42715821e-01,\n",
       "         -2.76526451e-01, -2.86143888e-02,  1.50711432e-01,\n",
       "         -1.92743227e-01, -2.56892771e-01],\n",
       "        [ 1.84297383e-01, -1.30851194e-01,  6.93398118e-02,\n",
       "          7.43058138e-03,  3.08160394e-01, -3.22147042e-01,\n",
       "         -4.55148593e-02, -3.30294669e-01],\n",
       "        [-2.14282572e-01, -2.33305544e-02,  2.96877295e-01,\n",
       "          1.56694099e-01, -2.24707693e-01, -3.78744006e-02,\n",
       "         -1.86342269e-01,  1.38293222e-01],\n",
       "        [-2.04084978e-01,  1.94721520e-01, -1.27084658e-01,\n",
       "          6.05460145e-02, -4.36814688e-02, -9.37780887e-02,\n",
       "         -3.04264814e-01, -2.76471645e-01],\n",
       "        [ 2.41320923e-01,  1.33916363e-01,  1.47173345e-01,\n",
       "         -1.76270857e-01, -2.69170612e-01, -3.26137394e-01,\n",
       "         -3.07322945e-02,  1.30429015e-01],\n",
       "        [-3.19772393e-01,  2.85892427e-01, -2.78827041e-01,\n",
       "          5.25678061e-02,  1.00010179e-01,  2.13428780e-01,\n",
       "         -2.35849500e-01, -2.16305926e-01],\n",
       "        [-1.73578218e-01,  1.15867462e-02, -2.94017971e-01,\n",
       "         -2.90311705e-02,  2.21346244e-01, -4.87416647e-02,\n",
       "          2.71316141e-01,  1.82933360e-01],\n",
       "        [-5.60542196e-02, -3.14283073e-01,  3.67914587e-02,\n",
       "          2.73144156e-01,  2.05587700e-01,  2.43701354e-01,\n",
       "         -6.18353859e-02,  2.92019099e-01],\n",
       "        [ 1.07895263e-01, -1.79079711e-01, -3.57781023e-01,\n",
       "          4.36210893e-02, -1.49586201e-01, -2.27498338e-01,\n",
       "         -7.21172616e-02, -2.27840856e-01],\n",
       "        [ 6.67383969e-02, -2.89911553e-02,  1.41857779e-02,\n",
       "         -1.08386345e-01,  1.86978597e-02, -1.59260228e-01,\n",
       "         -2.33625755e-01,  9.03702900e-02],\n",
       "        [ 7.77825788e-02, -1.63876891e-01,  1.31477356e-01,\n",
       "         -7.39591494e-02,  1.67165071e-01, -1.93786576e-01,\n",
       "          5.78498915e-02,  3.25365394e-01],\n",
       "        [ 1.95533987e-02, -1.88773759e-02, -2.13368908e-01,\n",
       "         -3.03296119e-01,  1.35304645e-01,  7.52098188e-02,\n",
       "          1.34989589e-01,  1.56682223e-01],\n",
       "        [-1.17762990e-01, -7.59814009e-02, -2.09789515e-01,\n",
       "         -3.55046168e-02, -1.70769483e-01,  2.45420486e-01,\n",
       "         -1.10337295e-01,  3.57313573e-01],\n",
       "        [-1.87337339e-01,  2.03479961e-01, -1.56539574e-01,\n",
       "          4.55989167e-02,  1.63795054e-01,  2.84621537e-01,\n",
       "         -4.54434231e-02,  2.05941960e-01],\n",
       "        [-2.54971441e-04,  2.05682330e-02,  3.32431830e-02,\n",
       "         -3.26706976e-01, -2.55813628e-01, -2.01561034e-01,\n",
       "          5.58004854e-03, -1.23128649e-02],\n",
       "        [-3.94601189e-02,  2.45303195e-02, -1.57698855e-01,\n",
       "         -1.29045889e-01,  2.45423838e-01, -3.92826609e-02,\n",
       "         -1.29161552e-01, -1.48323566e-01],\n",
       "        [-2.57459760e-01, -6.90145269e-02,  7.63984621e-02,\n",
       "          1.74385309e-01,  1.24687284e-01, -2.96602696e-01,\n",
       "         -2.02477127e-01, -1.72469556e-01]], dtype=float32),\n",
       " array([ 0.00427139, -0.00098175, -0.0093321 ,  0.00301045, -0.0132214 ,\n",
       "         0.00611323,  0.00167889,  0.00846135], dtype=float32)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A_clone.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Add the final dense layer with 1 neuron to the model_B_on_A.\n",
    "#Set the activation to \"sigmoid\", as this is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B_on_A.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Setting all layers except last as non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 51\n",
      "Non-trainable params: 275,750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B_on_A.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                    optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "161/161 [==============================] - 1s 3ms/step - loss: 0.3452 - accuracy: 0.8537 - val_loss: 0.2469 - val_accuracy: 0.9351\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9604 - val_loss: 0.1624 - val_accuracy: 0.9696\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9809 - val_loss: 0.1248 - val_accuracy: 0.9807\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9873 - val_loss: 0.1037 - val_accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.9893 - val_loss: 0.0904 - val_accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=5,\n",
    "                   validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.4984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03187718987464905, 0.49844881892204285]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B,y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0845453068614006, 0.9906928539276123]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B,y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:\n",
    "* Accuracy of model_B: 0.4984\n",
    "* Accuracy of model_B_on_A: 0.9907\n",
    "\n",
    "* **Even if acuuracy was similar, performance/training time/resources of model_B_on_A, are vastly reduced when compared with model_B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
